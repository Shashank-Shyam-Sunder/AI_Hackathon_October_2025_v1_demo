# ðŸ§© AI Cost Estimator â€” System Architecture

## ðŸ—ï¸ Overview

The **AI Cost Estimator** is a modular, Dockerized CLI application that collects user inputs, detects tasks using LLMs, and computes cost estimates for GenAI application development.

---

## ðŸ—‚ï¸ Project Folder Structure

```
.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ raw
â”‚   â”‚   â””â”€â”€ AI_Cost_Estimator_Catalog_UPDATED.xlsx
â”‚   â””â”€â”€ out                     # Generated outputs (auto-created after runs)
â”œâ”€â”€ docs
â”‚   â””â”€â”€ ARCHITECTURE.md
â”œâ”€â”€ src
â”‚   â””â”€â”€ app
â”‚       â”œâ”€â”€ cli
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ commands.py
â”‚       â”‚   â””â”€â”€ pipeline.py
â”‚       â”œâ”€â”€ core
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ cli_intake.py
â”‚       â”‚   â”œâ”€â”€ formulas.py
â”‚       â”‚   â”œâ”€â”€ plan_and_cost.py
â”‚       â”‚   â”œâ”€â”€ pricing_dict.py
â”‚       â”‚   â””â”€â”€ task_detect.py
â”‚       â”œâ”€â”€ llm
â”‚       â”‚   â”œâ”€â”€ providers
â”‚       â”‚   â”‚   â”œâ”€â”€ google.py
â”‚       â”‚   â”‚   â”œâ”€â”€ grok.py
â”‚       â”‚   â”‚   â”œâ”€â”€ openai.py
â”‚       â”‚   â”‚   â””â”€â”€ perplexity.py
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ config.py
â”‚       â”‚   â””â”€â”€ selector.py
â”‚       â”œâ”€â”€ utils
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ io_paths.py
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ utils
â”‚   â”œâ”€â”€ example_prompts.json
â”‚   â”œâ”€â”€ generate_root_folder_tree.py
â”‚   â””â”€â”€ clean_folder_structure.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Component Architecture

### 1. CLI Layer (`src/app/cli/`)
- **pipeline.py** â€” orchestrates the entire process (`intake â†’ detect â†’ plan_and_cost`).
- **commands.py** â€” defines CLI behavior and command-line entrypoints.

### 2. Core Logic (`src/app/core/`)
- **cli_intake.py** â€” handles interactive intake of app details and requirements.
- **task_detect.py** â€” uses LLMs to map user inputs to predefined catalog tasks.
- **plan_and_cost.py** â€” performs plan generation, cost computation, and output formatting.
- **formulas.py** â€” contains mathematical and cost-related formulas.
- **pricing_dict.py** â€” stores pricing references for models and APIs.

### 3. LLM Layer (`src/app/llm/`)
- **providers/** â€” abstraction for each supported LLM (OpenAI, Perplexity, Google, Grok).
- **selector.py** â€” picks the active provider dynamically at runtime.
- **config.py** â€” manages LLM configuration defaults (e.g., temperature, max_tokens).

### 4. Utilities
- **src/app/utils/io_paths.py** â€” central reference for I/O directories.
- **utils/example_prompts.json** â€” example prompts to test task detection.
- **utils/generate_root_folder_tree.py** â€” script to regenerate project tree documentation.

---

## ðŸ§¾ Data Flow

```mermaid
flowchart TD
    A["User Input via CLI"] --> B["Intake Module"]
    B --> C["Task Detection (LLM or rule-based)"]
    C --> D["Plan &amp; Cost Computation"]
    D --> E["Report Generation"]
    E --> F["data/out/(timestamp)/"]
```

**Explanation:**
1. **CLI Intake** â€” collects project details interactively.  
2. **Task Detection** â€” LLM identifies relevant tasks from catalog.  
3. **Plan & Cost** â€” computes minâ€“max cost estimates and generates reports.  
4. **Outputs** â€” all results are saved to timestamped folders under `data/out/`.

---

## ðŸ“Š Data Artifacts in `data/out/`

| File | Description |
|------|--------------|
| `intake_*.json` | User input metadata |
| `selected_tasks_*.json` | Tasks detected by the LLM |
| `explain_*.md` | Explanation for detected tasks |
| `cost_breakdown_*.json` | Per-task cost structure |
| `cost_summary_*.md` | Human-readable report |
| `run_meta.json` | Run metadata (timestamp, provider, etc.) |

---

## ðŸ§± Containerization

| File | Description |
|------|--------------|
| **Dockerfile** | Defines Python 3.12-slim image and installs dependencies. |
| **docker-compose.yml** | Mounts `data/` to persist outputs and loads `.env` API keys. |

Command to run:
```bash
docker compose run --rm app
```

---

## ðŸ§© Future Extensions
- Integration of automatic LLM-based report generation.
- Support for more pricing APIs.
- Web UI using FastAPI + Streamlit or React frontend.

---

## ðŸ§  Developer Note
The entire pipeline is CLI-first by design â€” all output paths, logs, and configurations are relative to the `data/` folder.  
To regenerate this document, run:
```bash
python utils/generate_root_folder_tree.py
```
---

# ðŸªª License
See [LICENSE](../LICENSE) for license details.
